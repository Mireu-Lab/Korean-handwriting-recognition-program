{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://mireu-server.iptime.org/api/public/dl/QLwEhRq3/DataSet/%EA%B0%9D%EC%B2%B4%EC%9D%B8%EC%8B%9D_%EC%97%B0%EA%B5%AC/13.%ED%95%9C%EA%B5%AD%EC%96%B4%EA%B8%80%EC%9E%90%EC%B2%B4/image_gen/new_image/gen_image.tar.gz\n",
    "# !tar -xzvf gen_image.tar.gz\n",
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "layerList = [\"가\", \"나\", \"다\"]\n",
    "# , \"라\", \"마\", \"바\", \"아\", \"자\", \"차\", \"카\", \"타\", \"파\", \"하\"\n",
    "\n",
    "all_x_array = []\n",
    "all_y_array = []\n",
    "\n",
    "for dir in layerList:\n",
    "    fileList = os.listdir(f\"../../dataset_dir/gen_image/{dir}\")[:6000]\n",
    "\n",
    "    for file in fileList:\n",
    "        y_array = dict.fromkeys(layerList, 0) # 12000개의 str 값을 0으로 초기화하는 dict 생성\n",
    "\n",
    "        imageData = Image.open(f\"\"\"../../dataset_dir/gen_image/{dir}/{file}\"\"\") # 이미지 tensor 데이터 출력\n",
    "        imageData = imageData.resize((32, 32)) # 이미지 다운스케일링\n",
    "\n",
    "        imageData = np.array(imageData)\n",
    "        all_x_array.append(imageData.tolist())\n",
    "\n",
    "        y_array[dir] = 1 # 사용자가 지정한 str 값을 1로 변경\n",
    "        y_array = list(y_array.values())\n",
    "        all_y_array.append(y_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = np.array(all_x_array)\n",
    "y_array = np.array(all_y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13498, 50, 50) (13498, 13)\n"
     ]
    }
   ],
   "source": [
    "print(x_array.shape, y_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x_array, y_array, test_size=0.2, shuffle=False, random_state=1004\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\") / 255\n",
    "Y_train = Y_train.astype(\"float32\") / 255\n",
    "\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "Y_test = Y_test.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w, image_h = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "X_train = X_train.reshape(-1, image_w, image_h, 1)\n",
    "X_test = X_test.reshape(-1, image_w, image_h, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10798, 50, 50, 1) (2700, 50, 50, 1)\n",
      "(10798, 13) (2700, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus: # 텐서플로가 첫 번째 GPU만 사용하도록 제한\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 접근 가능한 장치가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    keras.layers.Conv2D(32, (5, 5), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((3, 3)),\n",
    "    keras.layers.Conv2D(64, (4, 4), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(13, activation=\"softmax\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 46, 46, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 12, 12, 64)        32832     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 2, 2, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 13)                1677      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,861\n",
      "Trainable params: 174,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "85/85 [==============================] - 6s 61ms/step - loss: 343924.5625 - accuracy: 0.0825 - val_loss: 1140822.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "85/85 [==============================] - 5s 61ms/step - loss: 30100072.0000 - accuracy: 0.0783 - val_loss: 25593456.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "85/85 [==============================] - 5s 60ms/step - loss: 305055296.0000 - accuracy: 0.0729 - val_loss: 411524128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/85 [==============>...............] - ETA: 2s - loss: 860748480.0000 - accuracy: 0.0814"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\") \n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\") \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
