{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본 이미지 레이블 정렬화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "\n",
    "db = sqlite3.connect(\"../dataset.sqlite\")\n",
    "sql = db.cursor()\n",
    "\n",
    "\n",
    "lists = os.listdir(\"../dataset_dir/13.한국어글자체/original/\")\n",
    "lists = sorted(lists, key=lambda boxes: boxes[:-4])\n",
    "\n",
    "\n",
    "imageText = None\n",
    "\n",
    "\n",
    "for imageInfo in tqdm(lists):\n",
    "    try:\n",
    "        # SQL 구문 검색\n",
    "        sql.execute(f\"\"\"SELECT text FROM `handwriting_dataset` WHERE `image_id` = '{imageInfo[:-4]}'\"\"\")\n",
    "        imageText = sql.fetchone()\n",
    "    \n",
    "\n",
    "        # 레이블 디렉토리 생성\n",
    "        try:\n",
    "            os.mkdir(f\"../dataset_dir/13.한국어글자체/image/{imageText[0]}\") # 디렉토리 생성\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # 파일 복사\n",
    "        src = f\"../dataset_dir/13.한국어글자체/original/\"\n",
    "        dir = f\"../dataset_dir/13.한국어글자체/image/{imageText[0]}/\"\n",
    "        shutil.copyfile(src + imageInfo, dir + imageInfo) # 파일 복사\n",
    "\n",
    "    except TypeError:\n",
    "        print(imageInfo, imageText)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 레이블 저장 및 전체 묶음 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "dirList = os.listdir(\"../dataset_dir/13.한국어글자체/image\") # 이미지 레이어 리스트\n",
    "dirList = sorted(dirList) # 가나다 순으로 정렬\n",
    "\n",
    "\n",
    "for dir in tqdm(dirList):\n",
    "    fileList = os.listdir(f\"../dataset_dir/13.한국어글자체/image/{dir}/\") # 디랙토리 파일 리스트\n",
    "\n",
    "    # 이미지 업스케일링 파일 저장 디랙토리 생성\n",
    "    try:\n",
    "        os.mkdir(f\"../dataset_dir/13.한국어글자체/new_image/{dir}\") # 디렉토리 생성\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    for file in fileList:\n",
    "        imageData = Image.open(f\"\"\"../dataset_dir/13.한국어글자체/image/{dir}/{file}\"\"\").convert(\"L\") # 이미지 tensor 데이터 출력\n",
    "        imageData = imageData.resize((200, 200)) # 이미지 업스케일링\n",
    "\n",
    "        imageData.save(f\"\"\"../dataset_dir/13.한국어글자체/new_image/{dir}/{file}\"\"\") # 이미지 업스케일링 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "dirList = os.listdir(\"../dataset_dir/13.한국어글자체/image\") # 이미지 레이어 리스트\n",
    "dirList = sorted(dirList) # 가나다 순으로 정렬\n",
    "\n",
    "for dir in tqdm(dirList):\n",
    "    fileList = os.listdir(f\"../dataset_dir/13.한국어글자체/image/{dir}/\") # 디랙토리 파일 리스트\n",
    "\n",
    "    # npy 파일 저장 디랙토리 생성\n",
    "    try:\n",
    "        os.mkdir(f\"../dataset_dir/13.한국어글자체/image_npy/{dir}\") # 디렉토리 생성\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    dir_dataset_tensor = [] # 데이터셋 레이블\n",
    "    dir_label_tensor = [] # 데이터셋 레이블\n",
    "\n",
    "    for file in fileList:\n",
    "        tensor_label = dict.fromkeys(dirList, 0) # 12000개의 str 값을 0으로 초기화하는 dict 생성\n",
    "        tensor_label[dir[:-4]] = 1 # 사용자가 지정한 str 값을 1로 변경\n",
    "        tensor_label = list(tensor_label.values())\n",
    "\n",
    "        dir_label_tensor.append([tensor_label]) # 레이블 2차원 row 추가\n",
    "\n",
    "        imageData = Image.open(f\"\"\"../dataset_dir/13.한국어글자체/image/{dir}/{file}\"\"\").convert(\"L\") # 이미지 tensor 데이터 출력\n",
    "        imageData = imageData.resize((200, 200)) # 이미지 업스케일링\n",
    "\n",
    "        file_tensor = np.array(imageData) # 이미지 tensor 변환\n",
    "        file_tensor = file_tensor.reshape(-1) # tensor 1차원 변환\n",
    "\n",
    "        dir_dataset_tensor.append(file_tensor.tolist()) # 레이블 데이터셋 2차원 row 추가\n",
    "\n",
    "        np.save(f\"\"\"../dataset_dir/13.한국어글자체/image_npy/{dir}/{file[:-4]}_data\"\"\", file_tensor) # 이미지 데이터셋 파일 .npy 저장\n",
    "    np.save(f\"\"\"../dataset_dir/13.한국어글자체/image_npy/{dir}/{file[:-4]}_label\"\"\", dir_label_tensor) # 이미지 레이블 파일 .npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "dirList = os.listdir(\"../dataset_dir/13.한국어글자체/image\") # 이미지 레이어 리스트\n",
    "dirList = sorted(dirList) # 가나다 순으로 정렬\n",
    "\n",
    "dir_num = 1\n",
    "\n",
    "for dir in tqdm(dirList):\n",
    "    fileList = os.listdir(f\"../dataset_dir/13.한국어글자체/image/{dir}/\") # 디랙토리 파일 리스트\n",
    "\n",
    "    # 레이블 npy 파일 저장 디랙토리 생성\n",
    "    try:\n",
    "        os.mkdir(f\"../dataset_dir/13.한국어글자체/label_npy/{dir}\") # 디렉토리 생성\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    dir_dataset_tensor = np.array([]) # 데이터셋 레이블\n",
    "\n",
    "    for file in fileList:\n",
    "        imageData = Image.open(f\"\"\"../dataset_dir/13.한국어글자체/image/{dir}/{file}\"\"\").convert(\"L\") # 이미지 tensor 데이터 출력\n",
    "        imageData = imageData.resize((200, 200)) # 이미지 업스케일링\n",
    "\n",
    "        file_tensor = np.array(imageData) # 이미지 tensor 변환\n",
    "        file_tensor = file_tensor.reshape(-1) # tensor 1차원 변환\n",
    "\n",
    "        dir_dataset_tensor = np.r_[dir_dataset_tensor, file_tensor] # 레이블 데이터셋 2차원 row 추가\n",
    "    \n",
    "    np.save(f\"../dataset_dir/13.한국어글자체/label_npy/{dir}/{dir_num}_{dir}\", dir_dataset_tensor) # 레이블 데이터셋 파일 .npy 저장\n",
    "    \n",
    "    dir_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "dirList = os.listdir(\"../dataset_dir/13.한국어글자체/label_npy\") # 이미지 레이어 리스트\n",
    "dirList = sorted(dirList) # 가나다 순으로 정렬\n",
    "\n",
    "dir_num = 1\n",
    "all_dataset_tensor = np.array([]) # 데이터셋 레이블\n",
    "\n",
    "for dir in tqdm(dirList):\n",
    "    dir_tensor = np.load(f\"../dataset_dir/13.한국어글자체/label_npy/{dir}\")\n",
    "    dir_tensor.tolist()\n",
    "    dir_dataset_tensor = np.r_[dir_dataset_tensor, dir_tensor] # 레이블 데이터셋 2차원 row 추가\n",
    "\n",
    "np.save(f\"../dataset_dir/13.한국어글자체/label_npy/0_한국어_손글씨_데이터\", all_dataset_tensor) # 레이블 데이터셋 파일 .npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "dirList = os.listdir(\"../dataset_dir/13.한국어글자체/image\") # 이미지 레이어 리스트\n",
    "dirList = sorted(dirList) # 가나다 순으로 정렬\n",
    "\n",
    "dir_num = 1\n",
    "\n",
    "for dir in tqdm(dirList):\n",
    "    fileList = os.listdir(f\"../dataset_dir/13.한국어글자체/image/{dir}/\") # 디랙토리 파일 리스트\n",
    "\n",
    "    dir_dataset_tensor = [] # 데이터셋 레이블\n",
    "\n",
    "    for file in fileList:\n",
    "        imageData = Image.open(f\"\"\"../dataset_dir/13.한국어글자체/image/{dir}/{file}\"\"\").convert(\"L\") # 이미지 tensor 데이터 출력\n",
    "        imageData = imageData.resize((200, 200)) # 이미지 업스케일링\n",
    "\n",
    "        file_tensor = np.array(imageData) # 이미지 tensor 변환\n",
    "        file_tensor = file_tensor.reshape(-1) # tensor 1차원 변환\n",
    "\n",
    "        dir_dataset_tensor.append(file_tensor.tolist()) # 레이블 데이터셋 2차원 row 추가\n",
    "    \n",
    "    dir_dataset_tensor = np.array(dir_dataset_tensor)\n",
    "    np.save(f\"../dataset_dir/13.한국어글자체/label_npy/{dir}\", dir_dataset_tensor) # 레이블 데이터셋 파일 .npy 저장\n",
    "    \n",
    "    dir_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11171 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11171/11171 [09:22<00:00, 19.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "dirList = os.listdir(\"../dataset_dir/13.한국어글자체/label_npy\") # 이미지 레이어 리스트\n",
    "dirList = sorted(dirList) # 가나다 순으로 정렬\n",
    "\n",
    "dirList.remove(\"가.npy\")\n",
    "\n",
    "dir_num = 1\n",
    "all_label_tensor = []\n",
    "\n",
    "\n",
    "for dir in tqdm(dirList):\n",
    "    tensor_label = dict.fromkeys(dirList, 0) # 12000개의 str 값을 0으로 초기화하는 dict 생성\n",
    "    tensor_label[dir[:-4]] = 1 # 사용자가 지정한 str 값을 1로 변경\n",
    "    tensor_label = list(tensor_label.values())\n",
    "\n",
    "    all_label_tensor.append([tensor_label]) # 레이블 2차원 row 추가\n",
    "    \n",
    "    try:\n",
    "        all_dataset_tensor = np.load(f\"../dataset_dir/13.한국어글자체/label_npy/0_한국어_손글씨_데이터\")\n",
    "    except:\n",
    "        all_dataset_tensor = np.load(\"../dataset_dir/13.한국어글자체/label_npy/가.npy\") # 레이블\n",
    "\n",
    "    dir_tensor = np.load(f\"../dataset_dir/13.한국어글자체/label_npy/{dir}\")\n",
    "    all_dataset_tensor = np.concatenate((all_dataset_tensor, dir_tensor), axis=0) # 데이터셋 2차원 row 추가\n",
    "\n",
    "    np.save(f\"../dataset_dir/13.한국어글자체/label_npy/0_한국어_손글씨_데이터\", all_dataset_tensor) # 레이블 데이터셋 파일 .npy 저장\n",
    "np.save(f\"../dataset_dir/13.한국어글자체/label_npy/0_한국어_손글씨_레이블\", all_label_tensor) # 레이블 데이터셋 파일 .npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "model = LogisticRegression()\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=777)\n",
    "scores = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(\"cv set score :\", scores, \"\\ncv mean score :\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "model = LogisticRegression()\n",
    "shuffle_split = ShuffleSplit(test_size=0.5, train_size=0.5, n_splits=3, random_state=777)\n",
    "\n",
    "scores = cross_val_score(model, X, Y, cv=shuffle_split)\n",
    "\n",
    "print(\"cv set score :\", scores, \"\\ncv mean score :\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 : (101, 40000)\n",
      "레이블 : (11171, 1, 11172)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = np.load(\"../dataset_dir/13.한국어글자체/label_npy/0_한국어_손글씨_데이터.npy\")\n",
    "label = np.load(\"../dataset_dir/13.한국어글자체/label_npy/0_한국어_손글씨_레이블.npy\")\n",
    "\n",
    "print(f\"데이터셋 : {dataset.shape}\")\n",
    "print(f\"레이블 : {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 40000)\n",
      "(67, 40000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "npy1 = np.load(\"../dataset_dir/13.한국어글자체/label_npy/가.npy\")\n",
    "npy2 = np.load(\"../dataset_dir/13.한국어글자체/label_npy/나.npy\")\n",
    "\n",
    "print(npy1.shape)\n",
    "print(npy2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "imageData = Image.open(\"../dataset_dir/image/가/00004947.png\").convert(\"L\")\n",
    "imageData = imageData.resize((200, 200)) # 이미지 업스케일링\n",
    "\n",
    "file_tensor = np.array(imageData) # 이미지 tensor 변환\n",
    "\n",
    "print(file_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11172/11172 [18:04<00:00, 10.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "dirList = os.listdir(\"../dataset_dir/image\") # 이미지 레이어 리스트\n",
    "dirList = sorted(dirList) # 가나다 순으로 정렬\n",
    "\n",
    "for dir in tqdm(dirList):\n",
    "    fileList = os.listdir(f\"../dataset_dir/image/{dir}/\") # 디랙토리 파일 리스트\n",
    "\n",
    "    # npy 파일 저장 디랙토리 생성\n",
    "    try:\n",
    "        os.mkdir(f\"../dataset_dir/image_npy/{dir}\") # 디렉토리 생성\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    dir_dataset_tensor = [] # 데이터셋 레이블\n",
    "    dir_label_tensor = [] # 데이터셋 레이블\n",
    "\n",
    "    for file in fileList:\n",
    "        # tensor_label = dict.fromkeys(dirList, 0) # 12000개의 str 값을 0으로 초기화하는 dict 생성\n",
    "        # tensor_label[dir[:-4]] = 1 # 사용자가 지정한 str 값을 1로 변경\n",
    "        # tensor_label = list(tensor_label.values())\n",
    "\n",
    "        # dir_label_tensor.append([tensor_label]) # 레이블 2차원 row 추가\n",
    "\n",
    "        imageData = Image.open(f\"\"\"../dataset_dir/image/{dir}/{file}\"\"\").convert(\"L\") # 이미지 tensor 데이터 출력\n",
    "        imageData = imageData.resize((200, 200)) # 이미지 업스케일링\n",
    "\n",
    "        file_tensor = np.array(imageData) # 이미지 tensor 변환\n",
    "\n",
    "        dir_dataset_tensor.append(file_tensor.tolist()) # 레이블 데이터셋 2차원 row 추가\n",
    "\n",
    "        np.save(f\"\"\"../dataset_dir/image_npy/{dir}/{file[:-4]}_data\"\"\", file_tensor) # 이미지 데이터셋 파일 .npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 40000)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_concat_v.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
